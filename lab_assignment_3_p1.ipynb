{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_assignment_3_p1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuzAGJRExfZi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.layers import TextVectorization\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import layers, Input, Model\n",
        "from sklearn.metrics import precision_score, recall_score "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pathneg = 'rt-polarity.neg'\n",
        "X_pathpos = 'rt-polarity.pos'\n",
        "\n",
        "with open(X_pathneg, encoding = \"ISO-8859-1\") as file:\n",
        "    X_listneg = file.readlines()\n",
        "\n",
        "with open(X_pathpos, encoding = \"ISO-8859-1\") as file:\n",
        "    X_listpos = file.readlines()\n",
        " \n",
        "X_list = X_listneg + X_listpos\n",
        "y_list = [0]*len(X_listneg) + [1]*len(X_listpos)\n",
        "\n",
        "X_list = [classval[:-1] for classval in X_list]\n",
        "classes = np.unique(y_list)\n",
        "unique_letters = np.unique(X_list)"
      ],
      "metadata": {
        "id": "U3hVzB971G19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 100\n",
        "vectorizer = TextVectorization(max_tokens=20600, output_sequence_length=embed_dim)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(X_list).batch(128) ## Read batches of 128 samples\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "WQEsQqOdTTV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = vectorizer.get_vocabulary()\n",
        "vocab_to_index = dict(zip(vocab,range(len(vocab))))\n",
        "index_to_vocab = dict(zip(range(len(vocab)),vocab))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_list, y_list, train_size = 7/10, random_state = 1)\n",
        "\n",
        "X_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
        "X_test = vectorizer(np.array([[s] for s in X_test])).numpy()\n",
        "\n",
        "y_train = to_categorical(y_train).astype(np.int64)\n",
        "y_test = to_categorical(y_test).astype(np.int64)\n",
        "y_test_labels = np.argmax(y_test, axis = 1)"
      ],
      "metadata": {
        "id": "NoUe0CBx7y7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_per_sen = np.count_nonzero(X_test, axis = 1)\n",
        "pertile = np.array([np.percentile(words_per_sen,(1/3*100)), np.percentile(words_per_sen,(2/3*100))])\n",
        "\n",
        "shortind = np.nonzero(words_per_sen <= pertile[0])[0]\n",
        "mediumind = np.nonzero(np.logical_and(words_per_sen >= pertile[0], words_per_sen <= pertile[1]))[0]\n",
        "longind = np.nonzero(words_per_sen > pertile[1])[0]\n",
        "\n",
        "shortlist = [X_test[shortind,:], y_test[shortind,:], np.argmax(y_test[shortind,:], axis = 1)]\n",
        "mediumlist = [X_test[mediumind,:], y_test[mediumind,:], np.argmax(y_test[mediumind,:], axis = 1)]\n",
        "longlist = [X_test[longind,:], y_test[longind,:], np.argmax(y_test[longind,:], axis = 1)]"
      ],
      "metadata": {
        "id": "QjliEDmu2IW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class models:\n",
        "\n",
        "  def __init__(self, xtrain, ytrain, embed_layer):\n",
        "    self.X_train = xtrain\n",
        "    self.y_train = ytrain\n",
        "    self.embedding_layer = embed_layer\n",
        "    self.modmetrics = []\n",
        "\n",
        "  def get_metrics(self,ytest,ypred):\n",
        "    self.modmetrics.append([precision_score(ytest, ypred), recall_score(ytest, ypred)])\n",
        "    return self\n",
        "\n",
        "  def get_pred(self, X_test, y_test):\n",
        "    modpreds = np.argmax(self.savedmodel.predict(X_test), axis = 1)\n",
        "    y_test = np.argmax(y_test, axis = 1)\n",
        "    self.get_metrics(y_test,modpreds)\n",
        "    self.y_pred = modpreds\n",
        "    return self\n",
        "\n",
        "  def lstm_mod(self):\n",
        "    classes = self.y_train.shape[1]\n",
        "    int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
        "    embedded_sequences = self.embedding_layer(int_sequences_input)\n",
        "    x = layers.Bidirectional(layers.LSTM(20))(embedded_sequences)\n",
        "    preds = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "    model1 = Model(int_sequences_input, preds)\n",
        "    #model1.summary()\n",
        "\n",
        "    model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "    model1.fit(self.X_train, self.y_train, batch_size=128, epochs=2)\n",
        "    \n",
        "    self.savedmodel = model1\n",
        "\n",
        "    return self\n",
        "\n",
        "  def gru_mod(self):\n",
        "    classes = self.y_train.shape[1]    \n",
        "    int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
        "    embedded_sequences = self.embedding_layer(int_sequences_input)\n",
        "    x = layers.Bidirectional(layers.GRU(20))(embedded_sequences)\n",
        "    preds = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "    model2 = Model(int_sequences_input, preds)\n",
        "    #model2.summary()\n",
        "\n",
        "    model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "    model2.fit(self.X_train, self.y_train, batch_size=128, epochs=2)\n",
        "    \n",
        "    self.savedmodel = model2\n",
        "\n",
        "    return self\n",
        "\n",
        "  def rnn_mod(self):\n",
        "    classes = self.y_train.shape[1]\n",
        "    int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
        "    embedded_sequences = self.embedding_layer(int_sequences_input)\n",
        "    x = layers.Bidirectional(layers.SimpleRNN(20))(embedded_sequences)\n",
        "    preds = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "    model3 = Model(int_sequences_input, preds)\n",
        "    #model3.summary()\n",
        "\n",
        "    model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "    model3.fit(self.X_train, self.y_train, batch_size=128, epochs=2)\n",
        "\n",
        "    self.savedmodel = model3\n",
        "\n",
        "    return self"
      ],
      "metadata": {
        "id": "bJAFtB9E471R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(len(vocab), embed_dim, trainable=True)\n",
        "rnn_obj1 = models(X_train, y_train, embedding_layer).rnn_mod()\n",
        "rnn_obj1.get_pred(X_test, y_test)\n",
        "rnn_mets1 = rnn_obj1.modmetrics\n",
        "del rnn_obj1\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(len(vocab), embed_dim, trainable=True)\n",
        "lstm_obj1 = models(X_train, y_train, embedding_layer).lstm_mod()\n",
        "lstm_obj1.get_pred(X_test, y_test)\n",
        "lstm_mets1 = lstm_obj1.modmetrics\n",
        "del lstm_obj1\n",
        "\n",
        "embedding_layer = tf.keras.layers.Embedding(len(vocab), embed_dim, trainable=True)\n",
        "gru_obj1 = models(X_train, y_train, embedding_layer).gru_mod()\n",
        "gru_obj1.get_pred(X_test, y_test)\n",
        "gru_mets1 = gru_obj1.modmetrics\n",
        "del gru_obj1\n",
        "\n",
        "print(f'\\nThe RNN model\\'s precision is {rnn_mets1[0][0]} and the RNN model\\'s recall is {rnn_mets1[0][1]}')\n",
        "print(f'\\nThe LSTM model\\'s precision is {lstm_mets1[0][0]} and the LSTM model\\'s recall is {lstm_mets1[0][1]}')\n",
        "print(f'\\nThe GRU model\\'s precision is {gru_mets1[0][0]} and the GRU model\\'s recall is {gru_mets1[0][1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq9XIZOyxZGk",
        "outputId": "353e8032-004b-43db-f7cd-bd98e4f9387e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "59/59 [==============================] - 19s 298ms/step - loss: 0.6792\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 18s 301ms/step - loss: 0.3975\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 8s 43ms/step - loss: 0.6774\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 3s 44ms/step - loss: 0.4869\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 6s 43ms/step - loss: 0.6787\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 3s 43ms/step - loss: 0.4666\n",
            "\n",
            "The RNN model's precision is 0.6339479392624728 and the RNN model's recall is 0.7329153605015674\n",
            "\n",
            "The LSTM model's precision is 0.7684279191128506 and the LSTM model's recall is 0.7385579937304075\n",
            "\n",
            "The GRU model's precision is 0.741751269035533 and the GRU model's recall is 0.7329153605015674\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_obj2 = models(X_train, y_train, embedding_layer).rnn_mod()\n",
        "rnn_obj2.get_pred(shortlist[0], shortlist[1])\n",
        "rnn_obj2.get_pred(mediumlist[0], mediumlist[1])\n",
        "rnn_obj2.get_pred(longlist[0], longlist[1])\n",
        "rnn_mets_txt = rnn_obj2.modmetrics\n",
        "\n",
        "lstm_obj2 = models(X_train, y_train, embedding_layer).lstm_mod()\n",
        "lstm_obj2.get_pred(shortlist[0], shortlist[1])\n",
        "lstm_obj2.get_pred(mediumlist[0], mediumlist[1])\n",
        "lstm_obj2.get_pred(longlist[0], longlist[1])\n",
        "lstm_mets_txt = lstm_obj2.modmetrics\n",
        "\n",
        "gru_obj2 = models(X_train, y_train, embedding_layer).gru_mod()\n",
        "gru_obj2.get_pred(shortlist[0], shortlist[1])\n",
        "gru_obj2.get_pred(mediumlist[0], mediumlist[1])\n",
        "gru_obj2.get_pred(longlist[0], longlist[1])\n",
        "gru_mets_txt = gru_obj2.modmetrics\n",
        "\n",
        "print(rnn_mets_txt)\n",
        "print(lstm_mets_txt)\n",
        "print(gru_mets_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QymSFfoS_O3U",
        "outputId": "0c3730d6-a3d5-4fc5-e701-5c577143fca6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "59/59 [==============================] - 20s 306ms/step - loss: 0.4190\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 18s 302ms/step - loss: 0.2009\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 6s 43ms/step - loss: 0.5270\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 3s 43ms/step - loss: 0.2245\n",
            "Epoch 1/2\n",
            "59/59 [==============================] - 6s 43ms/step - loss: 0.5844\n",
            "Epoch 2/2\n",
            "59/59 [==============================] - 3s 46ms/step - loss: 0.2129\n",
            "[[0.7873684210526316, 0.6824817518248175], [0.77882797731569, 0.65814696485623], [0.6709677419354839, 0.6265060240963856]]\n",
            "[[0.791015625, 0.7390510948905109], [0.7743589743589744, 0.7236421725239617], [0.7350597609561753, 0.7409638554216867]]\n",
            "[[0.8320610687022901, 0.5967153284671532], [0.7719298245614035, 0.7028753993610224], [0.6948529411764706, 0.7590361445783133]]\n"
          ]
        }
      ]
    }
  ]
}