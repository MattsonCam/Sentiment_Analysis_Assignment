{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_assignment_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "UuzAGJRExfZi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from keras.layers import TextVectorization\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras import layers, Input, Model\n",
        "from sklearn.metrics import precision_score, recall_score "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pathneg = 'rt-polarity.neg'\n",
        "X_pathpos = 'rt-polarity.pos'\n",
        "\n",
        "with open(X_pathneg, errors='ignore') as file:\n",
        "    X_listneg = file.readlines()\n",
        "\n",
        "with open(X_pathpos, errors='ignore') as file:\n",
        "    X_listpos = file.readlines()\n",
        " \n",
        "X_list = X_listneg + X_listpos\n",
        "y_list = [0]*len(X_listneg) + [1]*len(X_listpos)\n",
        "\n",
        "X_list = [classval[:-1] for classval in X_list]\n",
        "classes = np.unique(y_list)\n",
        "unique_letters = np.unique(X_list)\n",
        "#class_to_index = dict((c,i) for i, c in enumerate(classes))"
      ],
      "metadata": {
        "id": "U3hVzB971G19"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 100\n",
        "vectorizer = TextVectorization(max_tokens=20500, output_sequence_length=embed_dim)\n",
        "text_ds = tf.data.Dataset.from_tensor_slices(X_list).batch(128) ## Read batches of 128 samples\n",
        "vectorizer.adapt(text_ds)"
      ],
      "metadata": {
        "id": "WQEsQqOdTTV3"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(vectorizer.get_vocabulary())) ## We set max_tokens=10000\n",
        "vocab = vectorizer.get_vocabulary()\n",
        "vocab_to_index = dict(zip(vocab,range(len(vocab))))\n",
        "index_to_vocab = dict(zip(range(len(vocab)),vocab))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_list, y_list, train_size = 7/10, random_state = 1)\n",
        "\n",
        "X_train = vectorizer(np.array([[s] for s in X_train])).numpy()\n",
        "X_test = vectorizer(np.array([[s] for s in X_test])).numpy()\n",
        "\n",
        "y_train = to_categorical(y_train).astype(np.int64)\n",
        "y_test = to_categorical(y_test).astype(np.int64)\n",
        "y_test_labels = np.argmax(y_test, axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoUe0CBx7y7x",
        "outputId": "f3f0fca4-8886-4d32-9ee1-feba9b331937"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20476\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_per_sen = np.count_nonzero(X_test, axis = 1)\n",
        "pertile = np.array([np.percentile(words_per_sen,(1/3*100)), np.percentile(words_per_sen,(2/3*100))])\n",
        "\n",
        "shortind = np.nonzero(words_per_sen <= pertile[0])[0]\n",
        "mediumind = np.nonzero(np.logical_and(words_per_sen >= pertile[0], words_per_sen <= pertile[1]))[0]\n",
        "longind = np.nonzero(words_per_sen > pertile[1])[0]\n",
        "\n",
        "shortlist = [X_test[shortind,:], y_test[shortind,:], np.argmax(y_test[shortind,:], axis = 1)]\n",
        "mediumlist = [X_test[mediumind,:], y_test[mediumind,:], np.argmax(y_test[mediumind,:], axis = 1)]\n",
        "longlist = [X_test[longind,:], y_test[longind,:], np.argmax(y_test[longind,:], axis = 1)]"
      ],
      "metadata": {
        "id": "QjliEDmu2IW5"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Embed a 1,000 word vocabulary into 5 dimensions.\n",
        "embedding_layer = tf.keras.layers.Embedding(len(vocab), embed_dim, trainable=True)\n",
        "modmetrics = []"
      ],
      "metadata": {
        "id": "kpvn9qX3gTU2"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving and recalling the model:\n",
        "class models:\n",
        "\n",
        "  def __init__(self, xtrain, ytrain, embed_layer):\n",
        "    self.X_train = xtrain\n",
        "    self.y_train = ytrain\n",
        "    self.embedding_layer = embed_layer\n",
        "    self.modmetrics = []\n",
        "\n",
        "  def conf_mat(self, y_test):\n",
        "    y_test = np.argmax(y_test, axis = 1)\n",
        "    conf_mat = confusion_matrix(y_test, self.y_pred)\n",
        "    return conf_mat\n",
        "\n",
        "  def get_metrics(self,ytest,ypred):\n",
        "    self.modmetrics.append([precision_score(ytest, ypred), recall_score(ytest, ypred)])\n",
        "    return self\n",
        "\n",
        "  def get_pred(self, X_test, y_test):\n",
        "    modpreds = np.argmax(self.savedmodel.predict(X_test), axis = 1)\n",
        "    y_test = np.argmax(y_test, axis = 1)\n",
        "    self.get_metrics(y_test,modpreds)\n",
        "    self.y_pred = modpreds\n",
        "    return self\n",
        "\n",
        "  def lstm_mod(self):\n",
        "    classes = self.y_train.shape[1]\n",
        "    int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
        "    embedded_sequences = self.embedding_layer(int_sequences_input)\n",
        "    x = layers.Bidirectional(layers.LSTM(20, return_sequences=True))(embedded_sequences)\n",
        "    x = layers.Bidirectional(layers.LSTM(20))(x)\n",
        "    preds = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "    model1 = Model(int_sequences_input, preds)\n",
        "    model1.summary()\n",
        "\n",
        "    model1.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "    model1.fit(self.X_train, self.y_train, batch_size=128, epochs=10)\n",
        "    self.savedmodel = model1\n",
        "\n",
        "    return self\n",
        "\n",
        "  def gru_mod(self):\n",
        "    classes = self.y_train.shape[1]\n",
        "    int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
        "    embedded_sequences = self.embedding_layer(int_sequences_input)\n",
        "    x = layers.Bidirectional(layers.GRU(20, return_sequences=True))(embedded_sequences)\n",
        "    x = layers.Bidirectional(layers.GRU(20))(x)\n",
        "    preds = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "    model2 = Model(int_sequences_input, preds)\n",
        "    model2.summary()\n",
        "\n",
        "    model2.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "    model2.fit(self.X_train, self.y_train, batch_size=128, epochs=10)\n",
        "    self.savedmodel = model2\n",
        "\n",
        "    return self\n",
        "\n",
        "  def rnn_mod(self):\n",
        "    classes = self.y_train.shape[1]\n",
        "    int_sequences_input = Input(shape=(None,), dtype=\"int64\")\n",
        "    embedded_sequences = self.embedding_layer(int_sequences_input)\n",
        "    x = layers.Bidirectional(layers.SimpleRNN(20, return_sequences=True))(embedded_sequences)\n",
        "    x = layers.Bidirectional(layers.SimpleRNN(20))(x)\n",
        "    preds = layers.Dense(classes, activation=\"softmax\")(x)\n",
        "    model3 = Model(int_sequences_input, preds)\n",
        "    model3.summary()\n",
        "\n",
        "    model3.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
        "    model3.fit(self.X_train, self.y_train, batch_size=128, epochs=10)\n",
        "    self.savedmodel = model3\n",
        "\n",
        "    return self"
      ],
      "metadata": {
        "id": "bJAFtB9E471R"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_obj = models(X_train, y_train, embedding_layer).rnn_mod()\n",
        "rnn_obj.get_pred(X_test, y_test)\n",
        "rnn_mets = rnn_obj.modmetrics\n",
        "\n",
        "lstm_obj = models(X_train, y_train, embedding_layer).lstm_mod()\n",
        "lstm_obj.get_pred(X_test, y_test)\n",
        "lstm_mets = lstm_obj.modmetrics\n",
        "\n",
        "gru_obj = models(X_train, y_train, embedding_layer).gru_mod()\n",
        "gru_obj.get_pred(X_test, y_test)\n",
        "gru_mets = gru_obj.modmetrics\n",
        "\n",
        "print(f'\\nThe RNN model\\'s precision is {rnn_mets[0][0]} and the RNN model\\'s recall is {rnn_mets[0][1]}')\n",
        "print(f'\\nThe LSTM model\\'s precision is {lstm_mets[0][0]} and the LSTM model\\'s recall is {lstm_mets[0][1]}')\n",
        "print(f'\\nThe GRU model\\'s precision is {gru_mets[0][0]} and the GRU model\\'s recall is {gru_mets[0][1]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq9XIZOyxZGk",
        "outputId": "9c6f733d-4350-4814-e711-684e67ea5eeb"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_31 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 100)         2047600   \n",
            "                                                                 \n",
            " bidirectional_60 (Bidirecti  (None, None, 40)         4840      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_61 (Bidirecti  (None, 40)               2440      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 82        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,054,962\n",
            "Trainable params: 2,054,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 34s 515ms/step - loss: 0.6901\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 29s 491ms/step - loss: 0.3775\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 30s 504ms/step - loss: 0.0617\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 29s 499ms/step - loss: 0.0109\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 29s 494ms/step - loss: 0.0043\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 29s 491ms/step - loss: 0.0027\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 29s 489ms/step - loss: 0.0019\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 29s 494ms/step - loss: 0.0015\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 29s 489ms/step - loss: 0.0012\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 30s 506ms/step - loss: 9.4715e-04\n",
            "Model: \"model_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_32 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 100)         2047600   \n",
            "                                                                 \n",
            " bidirectional_62 (Bidirecti  (None, None, 40)         19360     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_63 (Bidirecti  (None, 40)               9760      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 2)                 82        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,076,802\n",
            "Trainable params: 2,076,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 13s 95ms/step - loss: 0.6030\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 94ms/step - loss: 0.2700\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 96ms/step - loss: 0.1194\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 94ms/step - loss: 0.0487\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 94ms/step - loss: 0.0273\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0170\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0096\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0145\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 6s 93ms/step - loss: 0.0069\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 6s 94ms/step - loss: 0.0031\n",
            "Model: \"model_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_33 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 100)         2047600   \n",
            "                                                                 \n",
            " bidirectional_64 (Bidirecti  (None, None, 40)         14640     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_65 (Bidirecti  (None, 40)               7440      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 2)                 82        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,069,762\n",
            "Trainable params: 2,069,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 12s 93ms/step - loss: 0.5177\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 5s 92ms/step - loss: 0.0774\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 0.0153\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 0.0069\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 5s 92ms/step - loss: 0.0043\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 5s 92ms/step - loss: 0.0023\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 0.0013\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 0.0017\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 5s 92ms/step - loss: 0.0012\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 0.0013\n",
            "\n",
            "The RNN model's precision is 0.5740950226244343 and the RNN model's recall is 0.6363636363636364\n",
            "\n",
            "The LSTM model's precision is 0.7588555858310627 and the LSTM model's recall is 0.6984326018808777\n",
            "\n",
            "The GRU model's precision is 0.748062015503876 and the GRU model's recall is 0.7260188087774294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_obj = models(X_train, y_train, embedding_layer).rnn_mod()\n",
        "rnn_obj.get_pred(shortlist[0], shortlist[1])\n",
        "rnn_obj.get_pred(mediumlist[0], mediumlist[1])\n",
        "rnn_obj.get_pred(longlist[0], longlist[1])\n",
        "rnn_mets_txt = rnn_obj.modmetrics\n",
        "\n",
        "lstm_obj = models(X_train, y_train, embedding_layer).lstm_mod()\n",
        "lstm_obj.get_pred(shortlist[0], shortlist[1])\n",
        "lstm_obj.get_pred(mediumlist[0], mediumlist[1])\n",
        "lstm_obj.get_pred(longlist[0], longlist[1])\n",
        "lstm_mets_txt = lstm_obj.modmetrics\n",
        "\n",
        "gru_obj = models(X_train, y_train, embedding_layer).gru_mod()\n",
        "gru_obj.get_pred(shortlist[0], shortlist[1])\n",
        "gru_obj.get_pred(mediumlist[0], mediumlist[1])\n",
        "gru_obj.get_pred(longlist[0], longlist[1])\n",
        "gru_mets_txt = gru_obj.modmetrics\n",
        "\n",
        "print(rnn_mets_txt)\n",
        "print(lstm_mets_txt)\n",
        "print(gru_mets_txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QymSFfoS_O3U",
        "outputId": "b0410dd9-3532-4342-a4cd-9ca1d4271691"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_34 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 100)         2047600   \n",
            "                                                                 \n",
            " bidirectional_66 (Bidirecti  (None, None, 40)         4840      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_67 (Bidirecti  (None, 40)               2440      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 2)                 82        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,054,962\n",
            "Trainable params: 2,054,962\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 34s 499ms/step - loss: 0.1626\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 29s 490ms/step - loss: 0.0215\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 29s 489ms/step - loss: 0.0041\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 29s 489ms/step - loss: 0.0023\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 29s 486ms/step - loss: 0.0017\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 29s 498ms/step - loss: 0.0032\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 29s 501ms/step - loss: 0.0060\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 29s 495ms/step - loss: 0.0022\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 29s 489ms/step - loss: 0.0215\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 29s 493ms/step - loss: 0.0157\n",
            "Model: \"model_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_35 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 100)         2047600   \n",
            "                                                                 \n",
            " bidirectional_68 (Bidirecti  (None, None, 40)         19360     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_69 (Bidirecti  (None, 40)               9760      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 2)                 82        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,076,802\n",
            "Trainable params: 2,076,802\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 12s 95ms/step - loss: 0.3533\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 6s 94ms/step - loss: 0.0206\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0243\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 94ms/step - loss: 0.0158\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0068\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 6s 94ms/step - loss: 0.0032\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0162\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0077\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0216\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 6s 95ms/step - loss: 0.0101\n",
            "Model: \"model_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_36 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 100)         2047600   \n",
            "                                                                 \n",
            " bidirectional_70 (Bidirecti  (None, None, 40)         14640     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_71 (Bidirecti  (None, 40)               7440      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 2)                 82        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,069,762\n",
            "Trainable params: 2,069,762\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "59/59 [==============================] - 12s 93ms/step - loss: 0.4219\n",
            "Epoch 2/10\n",
            "59/59 [==============================] - 5s 92ms/step - loss: 0.0144\n",
            "Epoch 3/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 0.0019\n",
            "Epoch 4/10\n",
            "59/59 [==============================] - 6s 94ms/step - loss: 4.5855e-04\n",
            "Epoch 5/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 2.7065e-04\n",
            "Epoch 6/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 0.0019\n",
            "Epoch 7/10\n",
            "59/59 [==============================] - 5s 92ms/step - loss: 0.0019\n",
            "Epoch 8/10\n",
            "59/59 [==============================] - 6s 93ms/step - loss: 0.0063\n",
            "Epoch 9/10\n",
            "59/59 [==============================] - 5s 93ms/step - loss: 0.0025\n",
            "Epoch 10/10\n",
            "59/59 [==============================] - 5s 92ms/step - loss: 7.6289e-04\n",
            "[[0.7475915221579962, 0.708029197080292], [0.7255520504731862, 0.7348242811501597], [0.6548223350253807, 0.7771084337349398]]\n",
            "[[0.7768595041322314, 0.6861313868613139], [0.802734375, 0.6565495207667732], [0.7189542483660131, 0.6626506024096386]]\n",
            "[[0.744954128440367, 0.7408759124087592], [0.7517123287671232, 0.7012779552715654], [0.7134020618556701, 0.6947791164658634]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ],
      "metadata": {
        "id": "y-ow2apyi1yW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs"
      ],
      "metadata": {
        "id": "Qj0t7umGcY0p"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = len(vocab) \n",
        "\n",
        "hits = 0 ## number of words that were found in the pretrained model\n",
        "misses = 0 ## number of words that were missing in the pretrained model\n",
        "word_index = dict(zip(vocab, range(len(vocab))))\n",
        "# Prepare embedding matrix for our word list\n",
        "embedding_matrix = np.zeros((num_tokens, embed_dim))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "\n",
        "embedding_layer = Embedding(num_tokens, embed_dim,\n",
        "                            embeddings_initializer= Constant(embedding_matrix), \n",
        "                            trainable=False,\n",
        ")"
      ],
      "metadata": {
        "id": "Q4jCG6ZAckLx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rnn_obj = models(X_train, y_train, embedding_layer).rnn_mod()\n",
        "rnn_obj.get_pred(X_test, y_test)\n",
        "rnn_mets = rnn_obj.modmetrics\n",
        "\n",
        "lstm_obj = models(X_train, y_train, embedding_layer).lstm_mod()\n",
        "lstm_obj.get_pred(X_test, y_test)\n",
        "lstm_mets = lstm_obj.modmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        },
        "id": "eiS2gZ9FFfh-",
        "outputId": "e60b58e3-23b1-4e79-9da0-81177fd6de5b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_37 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 100)         2047600   \n",
            "                                                                 \n",
            " bidirectional_72 (Bidirecti  (None, None, 40)         4840      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " bidirectional_73 (Bidirecti  (None, 40)               2440      \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 2)                 82        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,054,962\n",
            "Trainable params: 7,362\n",
            "Non-trainable params: 2,047,600\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "24/59 [===========>..................] - ETA: 15s - loss: 0.7121"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-8013500eebb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrnn_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrnn_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrnn_mets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlstm_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_mod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-81-75cff4399405>\u001b[0m in \u001b[0;36mrnn_mod\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"categorical_crossentropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"adam\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavedmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "rnn_mat = rnn_obj.conf_mat(y_test)\n",
        "lstm_mat = lstm_obj.conf_mat(y_test)\n",
        "\n",
        "myax = sns.heatmap(rnn_mat.T, square = True, annot = True, fmt = 'd', \\\n",
        "cbar = False).set(title='RNN Confusion matrix with GloVE',xlabel='True Label', ylabel='Predicted Label')\n",
        "plt.show()\n",
        "plt.savefig('rnn_conf_mat.png')\n",
        "\n",
        "myax = sns.heatmap(lstm_mat.T, square = True, annot = True, fmt = 'd', \\\n",
        "cbar = False).set(title='LSTM Confusion matrix with GloVE',xlabel='True Label', ylabel='Predicted Label')\n",
        "plt.show()\n",
        "plt.savefig('lstm_conf_mat.png')\n",
        "print(f'\\nThe RNN model\\'s precision is {rnn_mets[0][0]} and the RNN model\\'s recall is {rnn_mets[0][1]}')\n",
        "print(f'\\nThe LSTM model\\'s precision is {lstm_mets[0][0]} and the LSTM model\\'s recall is {lstm_mets[0][1]}\\n')"
      ],
      "metadata": {
        "id": "n2Uh7lqsLXpz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}